{
 "metadata": {
  "name": "",
  "signature": "sha256:b880cc91ed2a210fda838b786799b483ead00c3297724652db9ea0e78110eb53"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import tensorflow as tf\n",
      "import numpy as np\n",
      "\n",
      "sess = tf.InteractiveSession()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "X_tr = np.load(\"train_X.npy\").astype(np.float32)\n",
      "y_tr = np.load(\"train_y.npy\").astype(np.float32)\n",
      "X_t = np.load(\"train_Xt.npy\").astype(np.float32)\n",
      "y_t = np.load(\"train_yt.npy\").astype(np.float32)\n",
      "print X_tr.shape, y_tr.shape, X_t.shape, y_t.shape\n",
      "dlen = X_tr.shape[0]\n",
      "idx = np.arange(dlen)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "(8000, 1000) (8000,) (2000, 1000) (2000,)\n"
       ]
      }
     ],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "x = tf.placeholder(\"float\", [None, 1000])\n",
      "y_ = tf.placeholder(\"int32\", [None,])\n",
      "keep_prob = tf.placeholder(tf.float32)\n",
      "n_len = 1024\n",
      "rand_v = tf.random_uniform((n_len, ))\n",
      "rand_v_bin = rand_v * 10000 < keep_prob * 10000\n",
      "scale = 1 / keep_prob\n",
      "rand_v_f = tf.to_float(rand_v_bin)\n",
      "print sess.run(rand_v_f, feed_dict={keep_prob: 0.5})\n",
      "\n",
      "w1 = tf.Variable(tf.truncated_normal(shape=[1000,n_len], stddev=0.1), name=\"aa_w1\")\n",
      "b1 = tf.Variable(tf.constant(0.1, shape=[n_len]), name=\"aa_b1\")\n",
      "layer1 = tf.nn.relu(tf.matmul(x,w1) + b1)\n",
      "#drop1 = tf.nn.dropout(layer1, keep_prob)\n",
      "#drop1 = layer1 * rand_v_f * scale\n",
      "\n",
      "\"\"\"\n",
      "l_mean = tf.reduce_mean(layer1, 0)\n",
      "l_diff = (layer1 - l_mean) * (layer1 - l_mean)\n",
      "l_diff_max = tf.reduce_max(l_diff, 0)\n",
      "l_diff_min = tf.reduce_min(l_diff, 0)\n",
      "d = -tf.log((l_diff_max - l_diff) / (l_diff_max-l_diff_min + 0.0000001) + 0.0000001)\n",
      "d_max = tf.reduce_max(d, 0)\n",
      "d_min = tf.reduce_min(d, 0)\n",
      "d_v = (1 - (d_max - d) / (d_max - d_min + 0.0000001))\n",
      "d_v_bin = d_v > (tf.reduce_mean(d_v) * keep_prob)\n",
      "muti_layer = layer1 * tf.to_float(d_v_bin)\n",
      "sess.run(tf.initialize_all_variables())\n",
      "print sess.run(muti_layer, feed_dict={\n",
      "    x: X_t,\n",
      "    y_: y_t,\n",
      "    keep_prob: 1\n",
      "})\n",
      "drop1 = muti_layer # * 255\n",
      "#tf.contrib.layers.batch_norm(muti_layer, scale=True)\n",
      "#drop1 = tf.contrib.layers.l2_regularizer(muti_layer)\n",
      "\n",
      "\"\"\"\n",
      "l_mean = tf.reduce_mean(layer1, 0)\n",
      "drop1 = tf.pow(layer1 - l_mean, 2)\n",
      "\n",
      "w2 = tf.Variable(tf.truncated_normal(shape=[n_len,n_len], stddev=0.1), name=\"ab_w1\")\n",
      "b2 = tf.Variable(tf.constant(0., shape=[n_len]), name=\"ab_b1\")\n",
      "layer2 = tf.nn.relu(tf.matmul(drop1,w2) + b2)\n",
      "drop = tf.nn.dropout(layer2, keep_prob)\n",
      "\"\"\"\n",
      "muti = layer1 * layer2\n",
      "muti_layer = muti - tf.reduce_mean(layer1, 0)\n",
      "#drop = tf.contrib.layers.batch_norm(muti_layer, scale=True, scope=\"aa_bn_\")\n",
      "drop = drop1 + layer2\n",
      "\"\"\"\n",
      "W = tf.Variable(tf.truncated_normal(shape=[n_len,10], stddev=0.1), name=\"aa_W\")\n",
      "B = tf.Variable(tf.constant(0.1, shape=[10]), name=\"aa_B\")\n",
      "y = tf.matmul(drop, W) + B\n",
      "#prevent_loss = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(muti_layer, tf.zeros_like(layer2)))\n",
      "cross_entropy = tf.reduce_mean(tf.nn.sparse_softmax_cross_entropy_with_logits(y, y_))\n",
      "#loss = cross_entropy + prevent_loss\n",
      "\n",
      "t_vars = tf.trainable_variables()\n",
      "d_vars = [var for var in t_vars if 'aa_' in var.name]\n",
      "g_vars = [var for var in t_vars if 'ab_' in var.name]\n",
      "\n",
      "train_step = tf.train.AdamOptimizer(0.001).minimize(cross_entropy, var_list=d_vars)\n",
      "#prevent_step = tf.train.AdamOptimizer(0.001).minimize(prevent_loss, var_list=g_vars)\n",
      "\n",
      "correct_prediction = tf.equal(tf.cast(tf.argmax(y,1), tf.int32), y_)\n",
      "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
      "\n",
      "sess.run(tf.initialize_all_variables())"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[ 0.  1.  0. ...,  0.  0.  0.]\n"
       ]
      }
     ],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "idx_i = 0\n",
      "idx_all = np.arange(dlen)\n",
      "batch_size = 32\n",
      "for i in range(20000):\n",
      "    if idx_i + batch_size >= dlen:\n",
      "        idx_i = 0\n",
      "        idx_all = np.random.permutation(idx_all)\n",
      "    idx = idx_all[idx_i: idx_i + batch_size]\n",
      "    idx_i += batch_size\n",
      "    fd = {\n",
      "        x: X_tr[idx].reshape(batch_size, 1000), \n",
      "        y_: y_tr[idx].reshape(batch_size, ), \n",
      "        keep_prob: 0.5,\n",
      "    }\n",
      "    #if i % 10 == 0:\n",
      "    #    sess.run(prevent_step, feed_dict=fd)\n",
      "    sess.run(train_step, feed_dict=fd)\n",
      "    if i % 1000 == 0:\n",
      "        print X_t.shape, y_t.shape\n",
      "        print i, (accuracy.eval(feed_dict={\n",
      "            x: X_t,\n",
      "            y_: y_t,\n",
      "            keep_prob: 1.0,\n",
      "        }))\n",
      "print i, (accuracy.eval(feed_dict={\n",
      "    x: X_t,\n",
      "    y_: y_t,\n",
      "    keep_prob: 1.0,\n",
      "}))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "(2000, 1000) (2000,)\n",
        "0 0.1635\n",
        "(2000, 1000)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " (2000,)\n",
        "1000 0.5915\n",
        "(2000, 1000)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " (2000,)\n",
        "2000 0.6265\n",
        "(2000, 1000)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " (2000,)\n",
        "3000 0.656\n",
        "(2000, 1000)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " (2000,)\n",
        "4000 0.6645\n",
        "(2000, 1000)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " (2000,)\n",
        "5000 0.641\n",
        "(2000, 1000)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " (2000,)\n",
        "6000 0.668\n",
        "(2000, 1000)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " (2000,)\n",
        "7000 0.703\n",
        "(2000, 1000)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " (2000,)\n",
        "8000 0.708\n",
        "(2000, 1000)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " (2000,)\n",
        "9000 0.7115\n",
        "(2000, 1000)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " (2000,)\n",
        "10000 0.7205\n",
        "(2000, 1000)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " (2000,)\n",
        "11000 0.7315\n",
        "(2000, 1000)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " (2000,)\n",
        "12000 0.721\n",
        "(2000, 1000)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " (2000,)\n",
        "13000 0.727\n",
        "(2000, 1000)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " (2000,)\n",
        "14000 0.7285\n",
        "(2000, 1000)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " (2000,)\n",
        "15000 0.7415\n",
        "(2000, 1000)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " (2000,)\n",
        "16000 0.7355\n",
        "(2000, 1000)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " (2000,)\n",
        "17000 0.7345\n",
        "(2000, 1000)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " (2000,)\n",
        "18000 0.735\n",
        "(2000, 1000)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " (2000,)\n",
        "19000 0.741\n",
        "19999"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 0.7425\n"
       ]
      }
     ],
     "prompt_number": 4
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}